{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1863b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "mouth_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "teeth_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "    \n",
    "    # Check for division by zero\n",
    "    if C == 0:\n",
    "        return 0\n",
    "    \n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def detect_blink(eye, threshold=0.2, consecutive_frames=3):\n",
    "    ear = eye_aspect_ratio(eye)\n",
    "    return ear < threshold, ear\n",
    "\n",
    "blink_frames = 0\n",
    "blink_count = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Detect eyes\n",
    "        eyes = eyes_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (255, 0, 0), 2)\n",
    "            cv2.putText(roi_color, 'Eye', (ex, ey - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 0), 2)\n",
    "            \n",
    "            # Detect blink\n",
    "            eye_gray = roi_gray[ey:ey+eh, ex:ex+ew]\n",
    "            is_blink, ear = detect_blink(eye_gray)\n",
    "            if is_blink:\n",
    "                blink_frames += 1\n",
    "                if blink_frames >= 3:\n",
    "                    blink_count += 1\n",
    "                    blink_frames = 0\n",
    "                cv2.putText(roi_color, 'Blink', (ex, ey + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            else:\n",
    "                blink_frames = 0\n",
    "        \n",
    "        # Detect mouths\n",
    "        mouths = mouth_cascade.detectMultiScale(roi_gray, scaleFactor=1.7, minNeighbors=11)\n",
    "        for (mx, my, mw, mh) in mouths:\n",
    "            cv2.rectangle(roi_color, (mx, my), (mx+mw, my+mh), (0, 0, 255), 2)\n",
    "            cv2.putText(roi_color, 'Mouth', (mx, my - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        # Detect teeth\n",
    "        teeth = teeth_cascade.detectMultiScale(roi_gray, scaleFactor=1.7, minNeighbors=11)\n",
    "        for (tx, ty, tw, th) in teeth:\n",
    "            cv2.rectangle(roi_color, (tx, ty), (tx+tw, ty+th), (0, 255, 255), 2)\n",
    "            cv2.putText(roi_color, 'Teeth', (tx, ty - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "    \n",
    "    # Display frame\n",
    "    cv2.imshow('Facial Features Detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9ba9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils import face_utils\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = dist.euclidean(mouth[2], mouth[10])  # 51, 59\n",
    "    B = dist.euclidean(mouth[4], mouth[8])  # 53, 57\n",
    "    C = dist.euclidean(mouth[0], mouth[6])  # 49, 55\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "MOUTH_AR_THRESH = 0.5\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "\n",
    "(mStart, mEnd) = (49, 68)\n",
    "(lStart, lEnd) = (42, 48)\n",
    "(rStart, rEnd) = (36, 42)\n",
    "\n",
    "COUNTER_BLINK = 0\n",
    "TOTAL_BLINKS = 0\n",
    "\n",
    "vs = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = vs.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    for rect in rects:\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        mouth = shape[mStart:mEnd]\n",
    "        mouthMAR = mouth_aspect_ratio(mouth)\n",
    "\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "        mouthHull = cv2.convexHull(mouth)\n",
    "        cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "        if mouthMAR > MOUTH_AR_THRESH:\n",
    "            cv2.putText(frame, \"Mouth is Open!\", (30, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER_BLINK += 1\n",
    "            if COUNTER_BLINK >= EYE_AR_CONSEC_FRAMES:\n",
    "                cv2.putText(frame, \"Blink Detected!\", (30, 90),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        else:\n",
    "            if COUNTER_BLINK >= EYE_AR_CONSEC_FRAMES:\n",
    "                TOTAL_BLINKS += 1\n",
    "            COUNTER_BLINK = 0\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vs.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff2a4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25854 sha256=620ef1f7cb73e611375c62ab5c82c6e01964cccca00345ce8ad36c1f0944b8c4\n",
      "  Stored in directory: c:\\users\\abhia\\appdata\\local\\pip\\cache\\wheels\\31\\d0\\2c\\87ce38f6052879e5b7b18f0f8b4a10ad2a9d210e908d449f16\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils import face_utils\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = dist.euclidean(mouth[14], mouth[18])  # 65, 67\n",
    "    B = dist.euclidean(mouth[12], mouth[16])  # 63, 61\n",
    "    C = dist.euclidean(mouth[0], mouth[6])  # 49, 55\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def detect_blink(eye, threshold=0.2, consecutive_frames=3):\n",
    "    ear = eye_aspect_ratio(eye)\n",
    "    return ear < threshold, ear\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "mouth_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "teeth_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "\n",
    "MOUTH_AR_THRESH = 0.6\n",
    "EYE_AR_THRESH = 0.25\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "TEETH_SCALE_FACTOR = 1.7\n",
    "TEETH_MIN_NEIGHBORS = 11\n",
    "\n",
    "(mStart, mEnd) = (49, 68)\n",
    "(lStart, lEnd) = (42, 48)\n",
    "(rStart, rEnd) = (36, 42)\n",
    "\n",
    "COUNTER_BLINK = 0\n",
    "TOTAL_BLINKS = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Mouth and eyes detection\n",
    "        rects = detector(gray, 0)\n",
    "        for rect in rects:\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "            mouth = shape[mStart:mEnd]\n",
    "            mouthMAR = mouth_aspect_ratio(mouth)\n",
    "\n",
    "            leftEye = shape[lStart:lEnd]\n",
    "            rightEye = shape[rStart:rEnd]\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "            if mouthMAR > MOUTH_AR_THRESH:\n",
    "                cv2.putText(frame, \"Mouth is Open!\", (30, 60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                COUNTER_BLINK += 1\n",
    "                if COUNTER_BLINK >= EYE_AR_CONSEC_FRAMES:\n",
    "                    cv2.putText(frame, \"Blink Detected!\", (30, 90),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            else:\n",
    "                if COUNTER_BLINK >= EYE_AR_CONSEC_FRAMES:\n",
    "                    TOTAL_BLINKS += 1\n",
    "                COUNTER_BLINK = 0\n",
    "\n",
    "        # Teeth detection\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        teeth = teeth_cascade.detectMultiScale(roi_gray, scaleFactor=TEETH_SCALE_FACTOR, minNeighbors=TEETH_MIN_NEIGHBORS)\n",
    "        for (tx, ty, tw, th) in teeth:\n",
    "            cv2.rectangle(frame, (x+tx, y+ty), (x+tx+tw, y+ty+th), (0, 255, 255), 2)\n",
    "            cv2.putText(frame, 'Teeth', (x+tx, y+ty - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow('Facial Features Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87310b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
